# -*- coding: utf-8 -*-
"""tab02-solyd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17A46r6WxN7X8fhMXxbTCk6uzt5W1iseR
"""

import re #biblioteca para expressoes regulares

import threading # biblioteca para mult-threadind- programaçao paralela

from sre_constants import error #biblioteca para sms de error

from bs4 import BeautifulSoup #biblioteca para manipular html e xml

import requests #biblioteca para requisicao

# crawler de telefones em site de anuncios - projeto da solyd TREINAMENTOS

DOMINIO = "https://django-anuncios.solyd.com.br" # dominio principal do site

URL_AUTOMOVEIS =  "https://django-anuncios.solyd.com.br/automoveis/" # caminho da url para a pagina de automoveis

LINKS = [] # lista vazia

TELEFONES = [] # lista vazia


def requisicao(url): # funcao de busca
  try:
    resposta = requests.get(url) # fazer a requisicao e armazenar na variavel
    if resposta.status_code == 200: #se a resposta da requisicao tiver codigo 200
      return resposta.text #retorne a variavel e armazene o texto
    else: # se nao, imprima uma mensagem de erro
      print("Erro ao fazer requisição.")
  except Exception as error: #imprima a mensagem de erro com o erro
    print("Erro ao fazer requisição.")
    print(error)

def parsing(resposta_html): # funcao de manipulacao do html com a biblioteca soup
  try:
   soup = BeautifulSoup(resposta_html, "html.parser")# variavel resposta do html como parametro  
   return soup #retone a variavel com a resposta
  except Exception as error: #se nao, imprima a sms de erro com o error
    print("Erro ao fazer o parsing HTML")
    print(error)

def encontrar_links(soup): #funcao para encontrar links com soup
  try:
    cards_pai = soup.find("div", class_="ui three doubling link cards") #pesquisar na clss
    cards = cards_pai.find_all("a") # pesquisar a tag a
  except:
    return None
    
  links = [] # lista vazia 
  for card in cards: # percorrer em cada card na lista de cards
    try:
      link = card['href'] # armazenar o href de cada card na lista
      links.append(link) #iteracao da lista dos links com metodo append 
    except:
      pass

  return links #retornando a lista com todos os links encontrados nos cards


def encontrar_telefone(soup): #função para encontrar telefone
  try:
    descricao = soup.findAll("div", class_="sixteen wide column")[2].p.get_text().strip() #usando o metodo findall do modulo soup para pegar os telefones
  except:
    return None

  # usando a expressao regular para fazer a busca de telefones. o r antes da expressao para transformar em raw
  regex = re.findall(r"\(?0?([1-9]{2})[ \-\.\)]{0,2}(9[ \-\.]?\d{4})[ \-\.]?(\d{4})",descricao)

  if regex:
    return regex

def descobrir_telefones():
  while True: # loop infinito para encontrar todos os links
    try:
      link_anuncio = LINKS.pop(0)
    except:
      return None

    resposta_anuncio = requisicao(DOMINIO + link_anuncio) # fazer uma requisicao no endereço da variavel DOMINIO e retornar o a variavel link_anuncio

    if resposta_anuncio:
      soup_anuncio = parsing(resposta_anuncio) # fazendo o parsing da informação recebida pela variavel
      if soup_anuncio:
        telefones = encontrar_telefone(soup_anuncio) # fazendo o parsing da informação recebida pela variavel encontrar_telefone
        if telefones:
          for telefone in telefones: # loop para acrescentar cada telefone na variavel telefones
            print("Telefone Encontrado: ", telefone) 
            TELEFONES.append(telefone) # acrescentrar telefone com o metodo append na lista vazia TELEFONES
            salvar_telefone(telefone) # chamando a funcao salvar_telefone para salvar cada  telefone


def salvar_telefone(telefone):
  string_telefone = "{}{}{}\n".format(telefone[0], telefone[1], telefone[2])  # formatando a string dos telefones
  try:
    with open("telefones.csv", "a") as arquivo: # criar um arquivo csv com o metodo open
      arquivo.write(string_telefone) # escrever no arquivo as informações da variavel string_telefone
      print("Telefone salvo com sucesso!") #imprimir se for salvo 
  except Exception as error: # se der errado exibir estas excessões
    print("Erro ao salvar arquivo")
    print(error)




if __name__ == "__main__": # se a variavel do nome do arquivo for igual ao main execute
  resposta_busca = requisicao(URL_AUTOMOVEIS) #chamando a funcao e passando a URL_AUTOMOVEIS como parametro
  if resposta_busca:
    soup_busca = parsing(resposta_busca) # se der certo, faça o parsing da variavel resposta_busca
    if soup_busca:
      LINKS = encontrar_links(soup_busca) # pegando a funcao encontrar_links e armazenando na variavel LINKS e passado soup_busca como parametro
      print("\o/crawler de telefones em site de anuncio\o/\n")
      
      THREADS = [] # lista de threads vazia
      for i in range(10): # loop para criar 10 threads
        t = threading.Thread(target=descobrir_telefones)
        THREADS.append(t) # acrescentar os threads na lista de threads

      for t in THREADS: # iniciar todos os threads
        t.start()

      for t in THREADS: # aguardar terminar as threads
        t.join()

      print("Todos os Telefones em lista: ", TELEFONES) # passando a variavel TELEFONES como parametro para mostrar os telefones